# Naïve Bayes

## O que é Naïve Bayes?
Naïve Bayes é um classificador probabilístico que se baseia no Teorema de Bayes. Ele é "ingênuo" (do inglês, naïve) porque assume que todos os atributos em um conjunto de dados são independentes entre si, o que raramente é verdade na vida real. Por exemplo, em uma frase, as palavras "Dinheiro" e "Grátis" provavelmente aparecem juntas, mas o Naïve Bayes ignora essa conexão e as trata como se não tivessem relação. Apesar dessa suposição simplista, o algoritmo é surpreendentemente rápido e eficaz, especialmente para problemas como a detecção de spam.

## Qual é o Grande Objetivo?
O objetivo do Naïve Bayes é calcular a probabilidade de um item (como uma mensagem de e-mail) pertencer a uma classe (como "Spam" ou "Normal") com base em seus atributos (as palavras na mensagem). Ele faz isso comparando a probabilidade de a mensagem ser Spam com a probabilidade de ser Normal e, em seguida, classifica a mensagem na classe que tiver a maior probabilidade.

## Como o Modelo Encontra a Solução?
A solução é encontrada através de um processo de duas etapas, usando probabilidades:

1. Probabilidades a Priori (Initial Guess): Primeiro, o modelo calcula a probabilidade a priori de uma mensagem ser Normal ou Spam, antes mesmo de olhar para o conteúdo da mensagem. Essa probabilidade é a proporção de mensagens Normais e Spam no conjunto de dados de treinamento.
2. Probabilidades Condicionais: Em seguida, o modelo calcula as probabilidades condicionais para cada palavra. Por exemplo, qual a probabilidade de ver a palavra "Dinheiro" dado que a mensagem é Spam?

Com essas duas informações, o modelo combina as probabilidades para calcular a probabilidade de a mensagem pertencer a cada classe:

- Para a classe Normal: Probabilidade (Normal) × Probabilidade (palavra 1 | Normal) × Probabilidade (palavra 2 | Normal)...
- Para a classe Spam: Probabilidade (Spam) × Probabilidade (palavra 1 | Spam) × Probabilidade (palavra 2 | Spam)...

O modelo então compara os dois resultados e classifica a mensagem na classe com o maior "score" (pontuação).

## Como o Modelo Avalia seu Desempenho?
O Naïve Bayes não tem um "treinamento" no sentido tradicional. Em vez disso, ele constrói histogramas ou tabelas de frequência das palavras para cada classe ("Normal" e "Spam"). Esses histogramas são usados para calcular as probabilidades de cada palavra. Para avaliar seu desempenho, o modelo utiliza os resultados de classificação:

- Classificação Final: Se o score para a classe Normal for 0.09 e para a classe Spam for 0.01, a mensagem é classificada como Normal porque a pontuação é maior.
- Lidando com Dados Ausentes: Se uma palavra em uma nova mensagem nunca apareceu no conjunto de treinamento de uma classe, a probabilidade dessa palavra para essa classe seria zero. Isso faria com que o score total para a classe também fosse zero. Para evitar isso, o Naïve Bayes adiciona uma contagem extra (chamada de pseudocount) a cada palavra em cada classe, garantindo que nenhuma probabilidade seja zero.

## Limitações do Naïve Bayes
A principal fraqueza do Naïve Bayes é sua suposição "ingênua" de independência. Em problemas do mundo real, as features (atributos) quase sempre dependem umas das outras. Ignorar essa dependência pode levar a classificações imprecisas. Além disso, o Naïve Bayes não considera a ordem das palavras, tratando "Amigo querido" da mesma forma que "Querido amigo", o que pode ser uma desvantagem em algumas análises.

Apesar dessas limitações, o Naïve Bayes continua sendo um algoritmo popular por sua simplicidade, velocidade e bom desempenho em tarefas de classificação de texto, especialmente quando o conjunto de dados de treinamento é grande.


## Como o Modelo Lida com Dados Contínuos?
A explicação anterior focou no Naïve Bayes para dados discretos (como a contagem de palavras). Quando os dados são contínuos (como medidas de peso, altura ou consumo de pipoca em gramas), o modelo não pode mais usar histogramas. Em vez disso, ele usa a distribuição de probabilidade normal (Gaussiana) para cada classe.

1. Para cada feature contínua, o modelo calcula a média e o desvio padrão dos dados de treinamento para cada classe (por exemplo, "Ama Troll 2" e "Não Ama Troll 2").
2. Com a média e o desvio padrão, o modelo pode desenhar uma curva Gaussiana. Essa curva representa a probabilidade de uma medida cair em um determinado valor para aquela classe.

Quando um novo dado chega, o modelo encontra a "altura" da curva Gaussiana nesse ponto específico. Essa altura, chamada de Likelihood, é a probabilidade de um valor específico ocorrer dado que ele pertence a uma certa classe.

## Como o Modelo Encontra a Solução com Dados Contínuos?
O processo de classificação é o mesmo: o modelo multiplica a probabilidade a priori pela likelihoods de cada feature contínua.

<img width="911" height="236" alt="image" src="https://github.com/user-attachments/assets/aea8c3a7-5d1b-42ce-b70e-6296055bc36a" />

O resultado com o maior score determina a classificação.

## Lidando com Probabilidades Muito Pequenas
Ao multiplicar várias probabilidades (que são números entre 0 e 1), o resultado pode se tornar extremamente pequeno, o que causa um problema de precisão em computadores chamado underflow.

Para resolver isso, o modelo aplica um logaritmo na equação. O logaritmo transforma a multiplicação de probabilidades em uma soma de logaritmos, o que evita o underflow e simplifica os cálculos. O resultado final é comparado em uma escala de logaritmos, e o que for maior ainda indica a classe mais provável.

## O Naïve Bayes e o Teorema de Bayes
As imagens mostram que o Naïve Bayes está diretamente ligado ao Teorema de Bayes, que é o seguinte:

<img width="264" height="73" alt="image" src="https://github.com/user-attachments/assets/333ba160-90ee-4245-b8d3-f3dc13c2c115" />


Na prática, a parte de baixo (o denominador) é a mesma para todas as classes e não muda o resultado da comparação, então ela é frequentemente omitida nos cálculos do algoritmo. Isso torna o Naïve Bayes mais simples e rápido, enquanto ainda se baseia nos fundamentos do Teorema de Bayes.

## Combinando Diferentes Tipos de Dados
O Naïve Bayes é flexível o suficiente para trabalhar com diferentes tipos de dados. É possível combinar a abordagem de histograma para dados discretos (como palavras) com a abordagem Gaussiana para dados contínuos (como tempo ou medidas).

Isso significa que, para uma única tarefa, como a classificação de e-mails, o modelo pode usar:

- A contagem de palavras do corpo do e-mail (dado discreto).
- E o tempo que levou para o e-mail chegar após o envio (dado contínuo).

Essa capacidade torna o Naïve Bayes uma ferramenta poderosa e adaptável para uma variedade de problemas de classificação.
